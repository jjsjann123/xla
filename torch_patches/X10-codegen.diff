diff --git a/aten/src/ATen/templates/aten_xla_type_default.cpp b/aten/src/ATen/templates/aten_xla_type_default.cpp
index 56c2916697..912b018579 100644
--- a/aten/src/ATen/templates/aten_xla_type_default.cpp
+++ b/aten/src/ATen/templates/aten_xla_type_default.cpp
@@ -1,5 +1,5 @@
 // ${generated_comment}
-#include <torch_xla/csrc/aten_xla_type_default.h>
+#include <lazy_xla/csrc/aten_xla_type_default.h>
 
 #include <ATen/Context.h>
 #include <torch/library.h>
@@ -8,9 +8,9 @@
 #include <tensorflow/compiler/xla/xla_client/debug_macros.h>
 #include <tensorflow/compiler/xla/xla_client/metrics.h>
 #include <tensorflow/compiler/xla/xla_client/tf_logging.h>
-#include <torch_xla/csrc/aten_xla_bridge.h>
-#include <torch_xla/csrc/aten_xla_type.h>
-#include <torch_xla/csrc/function_call_tracker.h>
+#include <lazy_tensor_core/csrc/aten_ltc_bridge.h>
+#include <lazy_tensor_core/csrc/function_call_tracker.h>
+#include <lazy_xla/csrc/aten_xla_type.h>
 
 namespace ${cpp_namespace} {
 
diff --git a/tools/codegen/dest/gen_external_aten_fallbacks.py b/tools/codegen/dest/gen_external_aten_fallbacks.py
index ee4a2c30d6..9003e14608 100644
--- a/tools/codegen/dest/gen_external_aten_fallbacks.py
+++ b/tools/codegen/dest/gen_external_aten_fallbacks.py
@@ -90,14 +90,14 @@ def xla_tensor_creation_api(
         # Only raw Tensor (non-reference) returns need to go through the XLA tensor creation API.
         # Tensor references can be returned directly, since they've already been converted to XLA tensors.
         # See Note [Tensor Copy Returns]
-        bridge_api = 'CreateXlaTensor'
+        bridge_api = 'CreateLtcTensor'
     elif isinstance(ret.type, ListType) and ret.type.elem == BaseType(BaseTy.Tensor):
-        bridge_api = 'CreateXlaTensors'
+        bridge_api = 'CreateLtcTensors'
     else:
         # for non tensor-types, there's no need to wrap the output in an xla bridge api.
         return ret_name
 
-    return f"bridge::{bridge_api}({cpu_result_name}, bridge::GetXlaDevice({device_param_name}))"
+    return f"bridge::{bridge_api}({cpu_result_name}, bridge::GetLtcDevice({device_param_name}))"
 
 
 
@@ -137,19 +137,19 @@ class GenExternalAtenFallback:
             return_names = cpp.return_names(g.out.native_function)
             if len(return_names) > 1:
                 updates = '\n  '.join(
-                    f'bridge::XlaUpdateTensors({{{ret_name}}}, {{std::get<{i}>({functional_result_name})}}, {{0}});'
+                    f'bridge::LtcUpdateTensors({{{ret_name}}}, {{std::get<{i}>({functional_result_name})}}, {{0}});'
                     for i, ret_name in enumerate(return_names))
                 returns = f'{dispatcher_sig.returns_type().cpp_type()}({", ".join(return_names)})'
             else:
                 ret_name = return_names[0]
-                updates = f'bridge::XlaUpdateTensors({{{ret_name}}}, {{{functional_result_name}}}, {{0}});'
+                updates = f'bridge::LtcUpdateTensors({{{ret_name}}}, {{{functional_result_name}}}, {{0}});'
                 returns = ret_name
 
             functional_sig = DispatcherSignature.from_schema(g.functional.native_function.func)
 
             return f"""\
 {dispatcher_sig.defn(name=func_name)} {{
-  XLA_FN_TRACK(3);
+  LTC_FN_TRACK(3);
   TF_VLOG(3) << "XLA {name} :"{print_args_str};
   auto {functional_result_name} = AtenXlaType::{functional_sig.name()}({", ".join(a.name for a in functional_sig.arguments())});
   {updates}
@@ -232,20 +232,20 @@ class GenExternalAtenFallback:
 
             tensorlist_intermediates_str = ''
             if len(tensorlist_args) > 0:
-                tensorlist_intermediates_str = '\n'.join([f'  auto {updated_name} = bridge::XlaCreateTensorList({arg.name});'
+                tensorlist_intermediates_str = '\n'.join([f'  auto {updated_name} = bridge::LtcCreateTensorList({arg.name});'
                                                           for arg, updated_name in tensorlist_args.items()])
 
             opt_tensor_intermediates_str = ''
             if len(opt_tensor_args) > 0:
                 arg_str = ", ".join([a.name for a in opt_tensor_args.keys()])
                 opt_tensor_intermediates_str = f'\n  std::vector<c10::optional<at::Tensor>> xlatens_opt_tensors = {{{arg_str}}};'
-                opt_tensor_intermediates_str += '\n  auto xlatens_opt = bridge::XlaCreateOptTensorList(xlatens_opt_tensors);'
+                opt_tensor_intermediates_str += '\n  auto xlatens_opt = bridge::LtcCreateOptTensorList(xlatens_opt_tensors);'
 
             intermediates = ''
             if tensorlist_intermediates_str != '':
                 intermediates += tensorlist_intermediates_str + '\n'
             intermediates += f"  std::vector<at::Tensor> xlatens_tensors = {{{', '.join([a.name for a in tensor_args.keys()])}}};"
-            intermediates += "\n  auto xlatens = bridge::XlaCreateTensorList(xlatens_tensors);"
+            intermediates += "\n  auto xlatens = bridge::LtcCreateTensorList(xlatens_tensors);"
             if opt_tensor_intermediates_str != '':
                 intermediates += opt_tensor_intermediates_str
 
@@ -278,7 +278,7 @@ class GenExternalAtenFallback:
             if len(annotated_tensor_indices) > 0:
                 indices_str = ", ".join([str(i) for i in annotated_tensor_indices])
                 collect_mutated_tensors = f'\n  std::vector<size_t> xlatens_update_indices = {{{indices_str}}};'
-                update_tensors = '\n  bridge::XlaUpdateTensors(xlatens_tensors, xlatens, xlatens_update_indices);'
+                update_tensors = '\n  bridge::LtcUpdateTensors(xlatens_tensors, xlatens, xlatens_update_indices);'
 
             returns = ''
             if f.native_function.func.returns:
@@ -300,8 +300,8 @@ class GenExternalAtenFallback:
 
             return f"""\
 {dispatcher_sig.defn(name=func_name)} {{
-  XLA_FN_TRACK(3);
-  XLA_COUNTER("aten::{name}", 1);
+  LTC_FN_TRACK(3);
+  LTC_COUNTER("aten::{name}", 1);
   TF_VLOG(3) << "XLA {name} :"{print_args_str};
 {intermediates}
   {at_call}{collect_mutated_tensors}{update_tensors}{avoid_warning}{return_str}
